apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: pyspark-job
  namespace: default
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "docker.io/library/localspark:latest"
  imagePullPolicy: Never
  mainApplicationFile: local:///mnt/job.py
  sparkVersion: "3.1.1"
  volumes:
    - name: "data-volume"
      hostPath:
        path: "/mnt"
        type: Directory
  restartPolicy:
    type: OnFailure
    onFailureRetries: 0
    onFailureRetryInterval: 1
    onSubmissionFailureRetries: 0
    onSubmissionFailureRetryInterval: 1
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.1.1
    serviceAccount: spark
    volumeMounts:
      - name: "data-volume"
        mountPath: "/mnt"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 3.1.1
    volumeMounts:
      - name: "data-volume"
        mountPath: "/mnt"
